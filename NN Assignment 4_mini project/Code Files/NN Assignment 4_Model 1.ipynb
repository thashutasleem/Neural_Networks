{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports Used\n",
    "<ul>\n",
    "    <li><b>Sequential</b> is used to create layer by layer Convolution Neural Network with Single input</li>\n",
    "    <li><b>Conv2D</b> is used to perform the first step => Convolution operation </li>\n",
    "    <li><b>MaxPooling2D</b> performs pooling operation. Here instead of using mean or min poling we used maxpooling as we have to give importance to the maximum weight pixel in the region of concern</li>\n",
    "    <li><b>Flatten</b> will convert the 2D array into 1D array</li>\n",
    "    <li><b>Dense</b> forms a fully conected neural network</li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "from keras.layers import MaxPooling2D\n",
    "\n",
    "from keras.layers import Flatten\n",
    "\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation and Compilation of Classifier\n",
    "\n",
    "\n",
    "In the below, Sequential() creates a classifier to which the various layers are added. Following describes the layers and their input parameters.\n",
    "<ol>\n",
    "    <li><b>Convolution Operation</b></li>\n",
    "        <ul>\n",
    "            <li>The first parameter in Conv2D is 32 which indicates the number of filters used.</li>\n",
    "            <li>The second parameter (3,3) is the shape of filter</li>\n",
    "            <li>The third paraeter indicates the shape of input image size which is 64x64x3 , 3 here stands for RGB</li>\n",
    "            <li>The fourth parameter is the activation function. Here it is  <b>\"RELU\"</b></li>\n",
    "\n",
    "        </ul>\n",
    "    <li><b>Maxpooling Operation</b></li>\n",
    "            The size of the pool is 2x2. Very small size is considered inorder to avoid pixel loss, so that we get precise location of where the feature is located.\n",
    "    <li><b>Flatten Operation</b></li>\n",
    "        This will convert 2D into 1D array so that it could be used in fully connected neural network. i.e., the next layer\n",
    "    <li><b>Fully Connected Layer</b></li>\n",
    "        In this the flattened output of the previous layer is given as the input. This layer can be considered as hidden layer as it lies inbetween the falttened inout and the ouput layer.\n",
    "        <ul>\n",
    "        <li>The first parameter units indicates the number of hidden nodes that are present in this layer.</li>\n",
    "        <li>The second parameter indicates the activation function used. In this case it is <b>\"RELU\"</b></li>\n",
    "        </ul>\n",
    "    <li><b>Output Layer</b></li>\n",
    "        This layer contains only one node, as it is a binary classifier we get to know if the image contains CAT or DOG. Sigmoid activation function is used here as it can easily reduce the output to 0 or 1.\n",
    "        \n",
    "</ol>\n",
    "\n",
    "After adding all the required layers we compile them in the end.\n",
    "<ul>\n",
    "    <li>Optimizer parameter \"adam\" indincates Stochoistic Gradient Descent Algorithm</li>\n",
    "    <li>Loss function choosen is Binary Cross Entropy</li>\n",
    "    <li>\"Accuracy\" is the performance metrics chosen</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "#Add Convolution layer\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "#Add Max Pooling layer\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "#Perform Flattening\n",
    "classifier.add(Flatten())\n",
    "#Add Fully Connected Network\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "#Final Output layer\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "#compile the classsifier\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1600 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n",
      "Found 2023 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,shear_range = 0.2,zoom_range = 0.2,horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "training_set = train_datagen.flow_from_directory('training_set',target_size = (64, 64),batch_size = 32,class_mode = 'binary')\n",
    "validation_set = train_datagen.flow_from_directory('validation_set',target_size = (64, 64),batch_size = 32,class_mode = 'binary')\n",
    "test_set = test_datagen.flow_from_directory('test_set',target_size = (64, 64),batch_size = 32,class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1600/1600 [==============================] - 400s 250ms/step - loss: 0.5095 - acc: 0.7480 - val_loss: 0.5724 - val_acc: 0.7315\n",
      "Epoch 2/10\n",
      "1600/1600 [==============================] - 448s 280ms/step - loss: 0.3110 - acc: 0.8657 - val_loss: 0.6626 - val_acc: 0.7395\n",
      "Epoch 3/10\n",
      "1600/1600 [==============================] - 440s 275ms/step - loss: 0.1608 - acc: 0.9390 - val_loss: 0.8654 - val_acc: 0.7289\n",
      "Epoch 4/10\n",
      "1600/1600 [==============================] - 450s 282ms/step - loss: 0.0809 - acc: 0.9726 - val_loss: 1.1711 - val_acc: 0.7039\n",
      "Epoch 5/10\n",
      "1600/1600 [==============================] - 443s 277ms/step - loss: 0.0530 - acc: 0.9828 - val_loss: 1.4644 - val_acc: 0.7079\n",
      "Epoch 6/10\n",
      "1600/1600 [==============================] - 446s 279ms/step - loss: 0.0428 - acc: 0.9855 - val_loss: 1.5372 - val_acc: 0.7166\n",
      "Epoch 7/10\n",
      "1600/1600 [==============================] - 456s 285ms/step - loss: 0.0326 - acc: 0.9895 - val_loss: 1.5508 - val_acc: 0.7284\n",
      "Epoch 8/10\n",
      "1600/1600 [==============================] - 466s 291ms/step - loss: 0.0258 - acc: 0.9913 - val_loss: 1.7487 - val_acc: 0.7165\n",
      "Epoch 9/10\n",
      "1600/1600 [==============================] - 434s 271ms/step - loss: 0.0252 - acc: 0.9915 - val_loss: 1.8884 - val_acc: 0.7113\n",
      "Epoch 10/10\n",
      "1600/1600 [==============================] - 441s 276ms/step - loss: 0.0261 - acc: 0.9916 - val_loss: 1.7523 - val_acc: 0.7186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcacc410668>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,steps_per_epoch = 1600,epochs = 10,validation_data = validation_set,validation_steps = 400,max_queue_size=7,workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Dogs:  1012\n",
      "Dogs :  856\n",
      "Cats :  156\n",
      "----------------------\n",
      "Total Cats:  1011\n",
      "Dogs :  559\n",
      "Cats :  452\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import glob\n",
    "data_path = os.path.join('./test_set/dogs/','*jpg')\n",
    "files = glob.glob(data_path)\n",
    "dog,cat,total=0,0,0\n",
    "for f in files:\n",
    "    test_image = image.load_img(f, target_size = (64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = classifier.predict(test_image)\n",
    "    training_set.class_indices\n",
    "    if result[0][0] == 1:\n",
    "        dog+=1\n",
    "    else:\n",
    "        cat+=1\n",
    "    total+=1\n",
    "print(\"Total Dogs: \",total)\n",
    "print(\"Dogs : \",dog)\n",
    "print(\"Cats : \",cat)\n",
    "print('----------------------')\n",
    "\n",
    "data_path = os.path.join('./test_set/cats/','*jpg')\n",
    "files = glob.glob(data_path)\n",
    "dog,cat,total=0,0,0\n",
    "for f in files:\n",
    "    test_image = image.load_img(f, target_size = (64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = classifier.predict(test_image)\n",
    "    training_set.class_indices\n",
    "    if result[0][0] == 1:\n",
    "        dog+=1\n",
    "    else:\n",
    "        cat+=1\n",
    "    total+=1\n",
    "print(\"Total Cats: \",total)\n",
    "print(\"Dogs : \",dog)\n",
    "print(\"Cats : \",cat)\n",
    "print('----------------------')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
